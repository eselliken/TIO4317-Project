{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIØ4317 Empirical Mini Project\n",
    "## Introduction\n",
    "Hva er dette prosjektet, formål osv. forklare litt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey, het_arch\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading the different csv-files that contain the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path\n",
    "data_path = \"data/\"\n",
    "\n",
    "# Load datasets\n",
    "zero_coupon = pd.read_csv(os.path.join(data_path, \"zero_coupon_rates.csv\"), delimiter=\";\")\n",
    "exchange_rates = pd.read_csv(os.path.join(data_path, \"usd_nok.csv\"), delimiter=\";\")\n",
    "inflation = pd.read_csv(os.path.join(data_path, \"kpi.csv\"), delimiter=\";\")\n",
    "osebx = pd.read_csv(os.path.join(data_path, \"osebx_prices.csv\"), delimiter=\";\")\n",
    "\n",
    "# Replace commas with dots in the KPI column and convert to float\n",
    "inflation[\"kpi\"] = inflation[\"kpi\"].str.replace(\",\", \".\").astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing Values\n",
    "Then, we check for missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"OSEBX\": osebx,\n",
    "    \"Zero Coupon\": zero_coupon,\n",
    "    \"Exchange Rates\": exchange_rates,\n",
    "    \"Inflation\": inflation\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    missing = df.isnull().sum()\n",
    "    missing_vars = missing[missing > 0]\n",
    "\n",
    "    if missing_vars.empty: \n",
    "        print(f\"{name}: No missing values.\")\n",
    "    else: # If missing values are present, print in which variables it is found. \n",
    "        print(f\"{name}: Missing values in {', '.join(missing_vars.index)}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, we can see that the data does not contain any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to Datetime format\n",
    "Next, we convert the dates to Datetime format.\n",
    "\n",
    "Since the inflation data is originally available only on a monthly basis, we apply linear interpolation to estimate daily values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to Datetime format\n",
    "osebx[\"Date\"] = pd.to_datetime(osebx[\"Date\"])\n",
    "zero_coupon[\"TIME_PERIOD\"] = pd.to_datetime(zero_coupon[\"TIME_PERIOD\"])\n",
    "exchange_rates[\"TIME_PERIOD\"] = pd.to_datetime(exchange_rates[\"TIME_PERIOD\"])\n",
    "inflation[\"Date\"] = pd.to_datetime(inflation[\"Date\"], format=\"%YM%m\")\n",
    "\n",
    "# Create a full date range from the first to last available date in your dataset\n",
    "full_date_range = pd.date_range(start=inflation[\"Date\"].min(), end=inflation[\"Date\"].max(), freq=\"D\")\n",
    "\n",
    "# Create a DataFrame with daily dates\n",
    "inflation_daily = pd.DataFrame({\"Date\": full_date_range})\n",
    "\n",
    "# Merge with the original inflation data (left join) and forward-fill missing values\n",
    "inflation_daily = inflation_daily.merge(inflation, on=\"Date\", how=\"left\")\n",
    "inflation_daily[\"kpi\"] = inflation_daily[\"kpi\"].interpolate(method=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute log returns for OSEBX\n",
    "Also, rename columns to ensure that all dataframes have a column named \"Date\", so that we can merge all datasets on \"Date\". After having merged all the datasets to one dataframe, we drop all the columns we are not interested in. Consequently, the columns we are left with are \"Date\", \"kpi\", \"zero_coupon_rate\", \"usd_nok_exchange_rate\", and \"log_return\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log returns\n",
    "osebx[\"log_return\"] = np.log(osebx[\"Close\"] / osebx[\"Close\"].shift(1))\n",
    "osebx.dropna(inplace=True)  # Drop the first row where return cannot be calculated\n",
    "\n",
    "# Rename columns to \"Date\"\n",
    "zero_coupon.rename(columns={\"TIME_PERIOD\": \"Date\"}, inplace=True)\n",
    "exchange_rates.rename(columns={\"TIME_PERIOD\": \"Date\"}, inplace=True)\n",
    "\n",
    "# Merge all datasets on 'Date'\n",
    "df = inflation_daily.merge(zero_coupon, on=\"Date\", how=\"inner\")\n",
    "df = df.merge(exchange_rates, on=\"Date\", how=\"inner\")\n",
    "df = df.merge(osebx, on=\"Date\", how=\"inner\") \n",
    "\n",
    "df = df.drop(columns=[\"Close\", \"High\", \"Low\", \"Open\", \"Volume\",\n",
    "       \"FREQ_x\", \"Frequency_x\", \"TENOR_x\", \"Tenor_x\", \"DECIMALS_x\",\n",
    "       \"FREQ_y\", \"Frequency_y\", \"BASE_CUR\", \"Base Currency\",\n",
    "       \"QUOTE_CUR\", \"Quote Currency\", \"TENOR_y\", \"Tenor_y\", \"DECIMALS_y\",\n",
    "       \"CALCULATED\", \"UNIT_MULT\", \"Unit Multiplier\", \"COLLECTION\",\n",
    "       \"Collection Indicator\"])\n",
    "\n",
    "df.rename(columns={\"OBS_VALUE_x\": \"zero_coupon_rate\"}, inplace=True)\n",
    "df.rename(columns={\"OBS_VALUE_y\": \"usd_nok_exchange_rate\"}, inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multicollinearity\n",
    "Check for multicollinearity by computing the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "selected_columns = [\"kpi\", \"usd_nok_exchange_rate\", \"zero_coupon_rate\"]\n",
    "corr_matrix = df[selected_columns].corr()\n",
    "\n",
    "# Visualize the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define highly correlated values to have a correlation coefficient >0.9. Because all variables have a correlation coefficient below 0.9, we decide to keep all of the explanatory variables. However, we notice that especially between usd_nok_exchange_rate and kpi and between zero_coupon_rate and kpi the correlation coefficient is close to the boundary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stationarity\n",
    "After having checked for correlation, we check for stationarity by applying the Augmented Dickey-Fuller (ADF) test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "# Check for stationarity \n",
    "def adf_test(series, var_name):\n",
    "    result = adfuller(series.dropna())  \n",
    "    status = \"Stationary\" if result[1] < 0.05 else \"Non-stationary\"\n",
    "\n",
    "    return [var_name, f\"{result[0]:.4f}\", f\"{result[1]:.4f}\", status]\n",
    "\n",
    "# Run ADF tests on all relevant variables\n",
    "stationarity = [\n",
    "    adf_test(df[\"log_return\"], \"Log Return\"),\n",
    "    adf_test(df[\"zero_coupon_rate\"], \"Zero Coupon Rate\"),\n",
    "    adf_test(df[\"usd_nok_exchange_rate\"], \"USD/NOK Exchange Rate\"),\n",
    "    adf_test(df[\"kpi\"], \"CPI\")\n",
    "]\n",
    "\n",
    "# Print results in a formatted table\n",
    "headers = [\"Variable\", \"ADF Statistic\", \"p-value\", \"Result\"]\n",
    "print(tabulate(stationarity, headers=headers, tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that the variables \"zero coupon rate,\" \"USD/NOK exchange rate,\" and \"CPI\" are non-stationary. To address this, we apply first differences to these columns, ensuring stationarity in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to stationary variables by applying first differences\n",
    "df[\"d_kpi\"] = df[\"kpi\"].diff()\n",
    "df[\"d_zero_coupon_rate\"] = df[\"zero_coupon_rate\"].diff()\n",
    "df[\"d_usd_nok_exchange_rate\"] = df[\"usd_nok_exchange_rate\"].diff()\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Run ADF tests after applying first differences on all relevant variables\n",
    "post_diff_stationarity = [\n",
    "    adf_test(df[\"d_zero_coupon_rate\"], \"Zero Coupon Rate\"),\n",
    "    adf_test(df[\"d_usd_nok_exchange_rate\"], \"USD/NOK Exchange Rate\"),\n",
    "    adf_test(df[\"d_kpi\"], \"CPI\")\n",
    "]\n",
    "\n",
    "# Print results in a table format\n",
    "headers = [\"Variable\", \"ADF Statistic\", \"p-value\", \"Stationarity\"]\n",
    "print(tabulate(post_diff_stationarity, headers=headers, tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, we can see that all the variables now are stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split percentage (e.g., 80% train, 20% test)\n",
    "split_idx = int(len(df) * 0.8)\n",
    "\n",
    "# Split the data\n",
    "train_df = df.iloc[:split_idx].copy()  # First 80% for training\n",
    "test_df = df.iloc[split_idx:].copy()   # Last 20% for testing\n",
    "\n",
    "# Define training and testing sets\n",
    "X_train, y_train = train_df[['d_kpi', 'd_zero_coupon_rate', 'd_usd_nok_exchange_rate']], train_df['log_return']\n",
    "X_test, y_test = test_df[['d_kpi', 'd_zero_coupon_rate', 'd_usd_nok_exchange_rate']], test_df['log_return']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression (MLR)\n",
    "### Autocorrelation\n",
    "Start by fitting a model to the training set, and then proceed to check for autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add constant for intercept\n",
    "X_train_ols = sm.add_constant(X_train)\n",
    "\n",
    "# Train OLS model\n",
    "ols_model = sm.OLS(y_train, X_train_ols).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to test for autocorrelation using Breusch-Godfrey test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breusch_godfrey_test(model, nlags=1):\n",
    "    # Perform the Breusch-Godfrey test\n",
    "    lm_stat, p_value, f_stat, f_p_value = acorr_breusch_godfrey(model, nlags=nlags)\n",
    "\n",
    "    # Print the test name and results\n",
    "    print(\"Breusch-Godfrey Test for Autocorrelation\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"LM Statistic: {lm_stat:.4f}\")\n",
    "    print(f\"P-Value: {p_value:.4f}\")\n",
    "    print(f\"F-Statistic: {f_stat:.4f}\")\n",
    "    print(f\"F-Test P-Value: {f_p_value:.4f}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # Interpretation of the p-value\n",
    "    if p_value < 0.05:\n",
    "        print(\"Autocorrelation detected in residuals (reject H0).\")\n",
    "    else:\n",
    "        print(\"No significant autocorrelation detected (fail to reject H0).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if autocorrelation is present in our model         \n",
    "breusch_godfrey_test(ols_model, nlags=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value of the Lagrange Multiplier statistic (LM) is \\<0.05 we reject H0. Since the p-value of the F-statistic is also \\< 0.05, it suggest that adding lagged variables could improve the model by removing autocorrelation. \n",
    "\n",
    "To get an impression of how many lags to use we visualize the partial autocorrelation function (PACF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PACF for 'log_return'\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot_pacf(df['log_return'], lags=21, method='ywm')\n",
    "plt.title(\"Partial Autocorrelation Function (PACF)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the partial autocorrelation coefficient for each lag, with the blue dashed lines representing the 95% confidence interval. Any bar extending this interval indicates statistical significance. From the figure, we observe that none of the lags appear to be highly significant. Therefore, we will continue adding lags until we no longer detect autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added lags\n",
    "lags = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
    "variables = ['d_kpi', 'd_zero_coupon_rate', 'd_usd_nok_exchange_rate']\n",
    "\n",
    "# Create lagged variables using a loop\n",
    "for var in variables:\n",
    "    for lag in lags:\n",
    "        train_df[f'{var}_lag{lag}'] = train_df[var].shift(lag)\n",
    "\n",
    "# Drop NaN values introduced by lagging\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "# Define independent variables dynamically\n",
    "X = train_df[[col for col in train_df.columns if col.startswith('d_kpi') or \n",
    "               col.startswith('d_zero_coupon_rate') or \n",
    "               col.startswith('d_usd_nok_exchange_rate')]]\n",
    "\n",
    "\n",
    "y_train = train_df['log_return']\n",
    "\n",
    "# Add a constant for intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the new OLS model\n",
    "lagged_model = sm.OLS(y_train, X).fit()\n",
    "\n",
    "# Check for autocorrelation again\n",
    "breusch_godfrey_test(lagged_model, nlags=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to add 28 lags to remove autocorrelation. However, including lagged variables to address autocorrelation introduces some issues. It violates the assumption that the explanatory variables are non-stochastic, and while it address autocorrelation, it also makes the model harder to interpret (SOURCE? Brooks, page 284-285) \n",
    "\n",
    "Given these problems, we revisited the PACF and observed that lag 7 and lag 18 appeared to be the most significant. Therefore, we decided to proceed with a model that includes only lag 7 and lag 18, even though autocorrelation is present. While ignoring autocorrelation keeps the coefficient estimates unbiased, the standard error estimates could be wrong. This could lead to unrealiable significance tests and potentially misleading conclusions (SOURCE?, Brooks, p. 276). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lags we want to keep\n",
    "keep_lags = [7, 18]\n",
    "\n",
    "# Keep only the original variables and the selected lagged variables\n",
    "columns_to_keep = ['d_kpi', 'd_zero_coupon_rate', 'd_usd_nok_exchange_rate']  # Original columns\n",
    "columns_to_keep += [f'{var}_lag{lag}' for var in variables for lag in keep_lags]  # Only lags 7 & 18\n",
    "\n",
    "# Select only the necessary columns\n",
    "train_df = train_df[columns_to_keep + ['log_return']]\n",
    "\n",
    "# Drop NaN values introduced by lagging\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "# Define independent and dependent variables\n",
    "X = train_df.drop(columns=['log_return'])\n",
    "y_train = train_df['log_return']\n",
    "\n",
    "# Add a constant for intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the new OLS model\n",
    "keep_lags_model = sm.OLS(y_train, X).fit()\n",
    "\n",
    "breusch_godfrey_test(keep_lags_model, nlags=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heteroskedasticity\n",
    "We continue by testing for heteroskedasticity. This is important because we assume homoskedasticity, which means that all the errors have the same variance. Identifying heteroskedasticity is important because it affects standard errors, confidence intervals, and hypothesis testing reliability in OLS regression.\n",
    "\n",
    "We test if the homoskedasticity assumption holds by using the ARCH test, as it is well-suited for time-series data because it detects time-dependent variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = keep_lags_model.resid\n",
    "\n",
    "arch_test = het_arch(residuals)\n",
    "\n",
    "print(f\"ARCH Test Statistic: {arch_test[0]}\")\n",
    "print(f\"p-value: {arch_test[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the strong heteroskedasticity identified by the ARCH test, we use heteroskedasticity-consistent (HC) standard error estimates. This is to ensure valid inference in our regression model. Since our training dataset consists of approximately 2000 observations, we choose HC3 since it is well-suited for medium to large sample sized. This improves the robustness of our statistical inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_robust = keep_lags_model.get_robustcov_results(cov_type='HC3')\n",
    "\n",
    "print(model_robust.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation\n",
    "Now, we want to evaluate the performance of our Multiple Linear Regression (MLR) model. In order to do this, we first need to add lag 7 and 18 to our test set.\n",
    "\n",
    "After having done this, we use the robust model to make predictions and compute the performance metrics Mean Absolute Percentage Error (MAPE), Mean Squared Error (MSE), and Mean Absolute Error (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "X_test = X_test.copy()\n",
    "\n",
    "X_test['d_kpi_lag7'] = X_test['d_kpi'].shift(7)\n",
    "X_test['d_zero_coupon_rate_lag7'] = X_test['d_zero_coupon_rate'].shift(7)\n",
    "X_test['d_usd_nok_exchange_rate_lag7'] = X_test['d_usd_nok_exchange_rate'].shift(7)\n",
    "\n",
    "X_test['d_kpi_lag18'] = X_test['d_kpi'].shift(18)\n",
    "X_test['d_zero_coupon_rate_lag18'] = X_test['d_zero_coupon_rate'].shift(18)\n",
    "X_test['d_usd_nok_exchange_rate_lag18'] = X_test['d_usd_nok_exchange_rate'].shift(18)\n",
    "\n",
    "# Drop rows with NaN values (first 18 rows will have NaNs due to lags)\n",
    "X_test = X_test.dropna()\n",
    "\n",
    "# Ensure y_test aligns with new X_test\n",
    "y_test = y_test.loc[X_test.index]  \n",
    "\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "y_pred = model_robust.predict(X_test)\n",
    "\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  \n",
    "mse = mean_squared_error(y_test, y_pred)  \n",
    "mae = mean_absolute_error(y_test, y_pred) \n",
    "\n",
    "results = [\n",
    "    [\"Metric\", \"Value\"],\n",
    "    [\"MAPE (%)\", f\"{mape:.4f}\"],\n",
    "    [\"MSE\", f\"{mse:.4f}\"],\n",
    "    [\"MAE\", f\"{mae:.4f}\"]\n",
    "]\n",
    "\n",
    "print(tabulate(results, headers=\"firstrow\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Percentage Error (MAPE)**\n",
    "\n",
    "A MAPE value of **244.0910%** indicates that, on average, the model's predictions deviate from the actual values by more than twice their magnitude. This indicates clearly that the model struggles to make accurate predictions, and is likely due to a combination of the model not being able to capture the complex dynamics in the explanatory variables and the fact that log returns are very small values. Therefore, a small mistake in the prediction can lead to a large percentage error.\n",
    "\n",
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "The MSE value of **0.0001** seems quite low, however, this is quite misleading. As noted earlier, the scale of the dependent variable is small, which makes the squared errors appear low even if the relative percentage error is large.\n",
    "\n",
    "**Mean Absolute Error (MAE)**\n",
    "\n",
    "The MAE value of **0.0061** represents the average absolute error in raw terms and indicates small deviations in absolute terms. However, the reason for such a low MAE value is the small scale of the dependent variable. This makes the absolute errors to seem small even if the relative error is large. \n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "While the MSE and MAE values appear low, the extremely high MAPE highly suggests that the model performs poorly in predicting the dependent variable. The small scale of the log returns of the OSEBX makes the absolute errors seem small but leads to large percentage errors. Also, the low **adjusted R squared value of 0.113** further confirms that the model has weak explanatory power. \n",
    "\n",
    "Overall, the model is not reliable for forecasting OSEBX returns and requires improvements, such as using a more sophisticated approach like ARIMAX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Elias og Erik\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Ensure the DataFrame is sorted by date\n",
    "df = df.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Define the dependent variable and exogenous regressors\n",
    "y = df[\"log_return\"]\n",
    "X = df[[\"zero_coupon_rate\", \"usd_nok_exchange_rate\", \"kpi\"]]\n",
    "\n",
    "# Split the data into training (80%) and testing (final 20%) sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "\n",
    "# Define ARIMAX order parameters (p, d, q)\n",
    "# This is a starting guess; you may refine these using AIC/BIC or a grid search\n",
    "order = (1, 0, 1)\n",
    "\n",
    "# Fit the ARIMAX model\n",
    "arimax_model = SARIMAX(endog=y_train, exog=X_train, order=order,\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False).fit(disp=False)\n",
    "\n",
    "# Print the ARIMAX model summary\n",
    "print(arimax_model.summary())\n",
    "\n",
    "# Ensure ARIMAX has been trained & has predictions\n",
    "forecast = arimax_model.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1, exog=X_test)\n",
    "\n",
    "# Compute R² for ARIMAX\n",
    "r2_arimax = r2_score(y_test, forecast)\n",
    "print(f\"ARIMAX R²: {r2_arimax:.4f}\")\n",
    "\n",
    "\n",
    "# Forecasting on the test set\n",
    "# Ensure that X_test is aligned with the forecast period\n",
    "forecast = arimax_model.predict(start=len(y_train),\n",
    "                                end=len(y_train) + len(y_test) - 1,\n",
    "                                exog=X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to check for multicolinearity using the the variance inflation factor (VIF). R^2 value is negative in this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Compute VIF for each predictor\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_train.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to difference the data since VIF >> 10 for both KPI and exchange rate, and zero coupon rate is also > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute first differences to remove trends\n",
    "df[\"diff_kpi\"] = df[\"kpi\"].diff()\n",
    "df[\"diff_usd_nok\"] = df[\"usd_nok_exchange_rate\"].diff()\n",
    "df[\"diff_zero_coupon\"] = df[\"zero_coupon_rate\"].diff()\n",
    "\n",
    "# Drop NaN values created by differencing\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define dependent variable (unchanged)\n",
    "y_df = df[\"log_return\"]\n",
    "\n",
    "# Use differenced exogenous variables\n",
    "X_df = df[[\"diff_zero_coupon\", \"diff_usd_nok\", \"diff_kpi\"]]\n",
    "\n",
    "# Split into training and test sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "y_train_df, y_test_df = y_df[:train_size], y_df[train_size:]\n",
    "X_train_df, X_test_df = X_df[:train_size], X_df[train_size:]\n",
    "\n",
    "# Compute VIF for each predictor\n",
    "vif_data_df = pd.DataFrame()\n",
    "vif_data_df[\"Feature\"] = X_train.columns\n",
    "vif_data_df[\"VIF\"] = [variance_inflation_factor(X_train_df.values, i) for i in range(X_train.shape[1])]\n",
    "\n",
    "print(vif_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the differenced data, lets try setting up the ARIMAX model again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ARIMAX order\n",
    "order = (1, 0, 1) \n",
    "\n",
    "# Fit the ARIMAX model\n",
    "arimax_model = SARIMAX(endog=y_train, exog=X_train, order=order,\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False).fit(disp=False)\n",
    "\n",
    "# Print model summary\n",
    "print(arimax_model.summary())\n",
    "\n",
    "# Forecasting\n",
    "forecast = arimax_model.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1, exog=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to iterate through different orders to find the optimal one. (Denne er nok litt for eksperimentell i beste case, her tror jeg kunnskapen om PACF og ACF er mer riktig XD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the range of (p, d, q) values to test\n",
    "p_values = range(0, 4)  # Test AR terms from 0 to 3\n",
    "d_values = [0]          # Assume stationarity (no differencing)\n",
    "q_values = range(0, 4)  # Test MA terms from 0 to 3\n",
    "\n",
    "best_r2 = -float(\"inf\")  # Start with a very low R²\n",
    "best_order = None\n",
    "results = []\n",
    "\n",
    "# Loop over all (p, d, q) combinations\n",
    "for p, d, q in itertools.product(p_values, d_values, q_values):\n",
    "    try:\n",
    "        # Fit the ARIMAX model with given (p, d, q)\n",
    "        model = SARIMAX(y_train_df, exog=X_train_df, order=(p, d, q),\n",
    "                        enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
    "\n",
    "        # Generate predictions\n",
    "        forecast = model.predict(start=len(y_train_df), end=len(y_train_df) + len(y_test_df) - 1, exog=X_test_df)\n",
    "\n",
    "        # Compute R²\n",
    "        r2 = r2_score(y_test_df, forecast)\n",
    "\n",
    "        # Store results\n",
    "        results.append((p, d, q, r2))\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_order = (p, d, q)\n",
    "\n",
    "        print(f\"Tested ARIMAX({p},{d},{q}) → R²: {r2:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping ARIMAX({p},{d},{q}) due to error: {e}\")\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "results_df = pd.DataFrame(results, columns=[\"p\", \"d\", \"q\", \"R2\"]).sort_values(by=\"R2\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resulting forecast against the test data. Using the differenced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_train_df.index, y_train_df, label=\"Training Data\")\n",
    "plt.plot(y_test_df.index, y_test_df, label=\"Test Data\", color='gray')\n",
    "plt.plot(y_test_df.index, forecast_df, label=\"ARIMAX Forecast\", color='red')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Log Return\")\n",
    "plt.title(\"ARIMAX Model Forecast vs Actual\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
